{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solved challenging problems in computer vision. Specifically, you'll use networks trained on [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html). \n",
    "\n",
    "ImageNet is a massive dataset with over 1 million labeled images in 1000 categories. It's used to train deep neural networks using an architecture called convolutional layers. I'm not going to get into the details of convolutional networks here, but if you want to learn more about them, please [watch this](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "Once trained, these models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called transfer learning. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With `torchvision.models` you can download these pre-trained networks and use them in your applications. We'll include `models` in our imports now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pretrained models require the input to be 224x224 images. Also, we'll need to match the normalization used when the models were trained. Each color channel was normalized separately, the means are `[0.485, 0.456, 0.406]` and the standard deviations are `[0.229, 0.224, 0.225]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 1.4440,  1.4440,  1.4269,  ...,  1.9407,  1.8722,  1.4269],\n",
       "           [ 1.4612,  1.4612,  1.4783,  ...,  1.7865,  1.8550,  1.8550],\n",
       "           [ 1.4954,  1.4440,  1.4612,  ...,  1.1529,  1.8208,  1.7694],\n",
       "           ...,\n",
       "           [ 0.3823,  0.3994, -0.0972,  ...,  1.6495,  1.1015,  1.1358],\n",
       "           [ 0.3652,  0.4851,  0.3823,  ...,  1.7523,  1.3413,  1.9064],\n",
       "           [ 0.0741, -0.0287,  0.3309,  ...,  1.7180,  1.6838,  1.9749]],\n",
       " \n",
       "          [[ 1.8158,  1.8508,  1.8683,  ...,  2.1310,  2.0609,  1.6057],\n",
       "           [ 1.8158,  1.8158,  1.8333,  ...,  1.9734,  2.0434,  2.0434],\n",
       "           [ 1.8333,  1.7808,  1.7983,  ...,  1.3431,  2.0084,  1.9559],\n",
       "           ...,\n",
       "           [ 0.6954,  0.7129,  0.2052,  ...,  1.7633,  1.1856,  1.2381],\n",
       "           [ 0.6779,  0.8004,  0.6954,  ...,  1.8508,  1.4482,  2.0259],\n",
       "           [ 0.3978,  0.2752,  0.6604,  ...,  1.8158,  1.7633,  2.0609]],\n",
       " \n",
       "          [[ 2.0300,  2.0648,  2.0648,  ...,  2.4134,  2.3611,  1.9080],\n",
       "           [ 2.0474,  2.0474,  2.0823,  ...,  2.2043,  2.3088,  2.3263],\n",
       "           [ 2.0823,  2.0300,  2.0474,  ...,  1.5768,  2.2566,  2.2566],\n",
       "           ...,\n",
       "           [ 1.0714,  1.0888,  0.5834,  ...,  1.8208,  1.2457,  1.2980],\n",
       "           [ 1.0539,  1.1759,  1.0714,  ...,  1.9080,  1.5071,  2.0823],\n",
       "           [ 0.7228,  0.6182,  0.9842,  ...,  1.8731,  1.8383,  2.1171]]],\n",
       " \n",
       " \n",
       "         [[[-1.3473,  0.5364,  0.2624,  ...,  0.0227,  0.2624, -0.1486],\n",
       "           [-1.3473, -0.9877,  0.0741,  ..., -0.0287, -0.3027,  0.5364],\n",
       "           [-1.1247, -1.3815, -1.1247,  ...,  0.1597, -0.1828,  0.3309],\n",
       "           ...,\n",
       "           [ 1.6838,  0.9988,  0.2796,  ..., -1.4329, -1.1247, -1.0048],\n",
       "           [ 0.8447, -0.0972,  0.1597,  ..., -0.7308, -0.4911, -1.2788],\n",
       "           [ 0.2282,  0.3994,  0.1254,  ...,  0.0398, -0.4739, -1.6555]],\n",
       " \n",
       "          [[-1.4055,  0.6604,  0.5028,  ...,  0.4328,  0.5028, -0.0049],\n",
       "           [-1.3704, -0.8803,  0.3277,  ...,  0.3978, -0.0574,  0.6604],\n",
       "           [-1.1429, -1.2654, -0.8452,  ...,  0.6078,  0.0826,  0.4503],\n",
       "           ...,\n",
       "           [ 1.9909,  1.2906,  0.5378,  ..., -1.3529, -1.0028, -0.8452],\n",
       "           [ 1.1681,  0.1702,  0.4328,  ..., -0.6176, -0.3725, -1.1604],\n",
       "           [ 0.5553,  0.7129,  0.4328,  ...,  0.1702, -0.3725, -1.5630]],\n",
       " \n",
       "          [[-1.4907,  0.4614,  0.2522,  ..., -0.0964,  0.0431, -0.4101],\n",
       "           [-1.4384, -1.0376,  0.0605,  ..., -0.2358, -0.6193,  0.1476],\n",
       "           [-1.2816, -1.4210, -1.1247,  ..., -0.1487, -0.6193, -0.1487],\n",
       "           ...,\n",
       "           [ 1.3677,  0.6531, -0.0964,  ..., -1.2293, -0.8981, -0.7936],\n",
       "           [ 0.4439, -0.5495, -0.3055,  ..., -0.4973, -0.2707, -1.0898],\n",
       "           [-0.2707, -0.1312, -0.4101,  ...,  0.2173, -0.2881, -1.5256]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2489,  2.2318,  2.1975,  ...,  1.6838,  1.1700,  0.6049],\n",
       "           [ 2.2489,  2.2318,  2.1975,  ...,  1.7865,  1.0159,  0.8276],\n",
       "           [ 2.2489,  2.2318,  2.1975,  ...,  1.8379,  0.6563,  0.5878],\n",
       "           ...,\n",
       "           [ 2.2318,  2.2318,  2.2318,  ..., -0.6965, -0.9534, -1.1247],\n",
       "           [ 2.2318,  2.2489,  2.2489,  ..., -0.6281, -0.8164, -0.9020],\n",
       "           [ 2.1975,  2.2147,  2.2318,  ..., -0.9705, -0.5767, -0.4397]],\n",
       " \n",
       "          [[ 2.4286,  2.4111,  2.3761,  ...,  1.5707,  1.0105,  0.4153],\n",
       "           [ 2.4286,  2.4111,  2.3761,  ...,  1.7283,  0.9055,  0.6604],\n",
       "           [ 2.4286,  2.4111,  2.3761,  ...,  1.8508,  0.5728,  0.4503],\n",
       "           ...,\n",
       "           [ 2.3936,  2.3936,  2.3936,  ..., -0.0049, -0.3025, -0.4951],\n",
       "           [ 2.4111,  2.4286,  2.4286,  ...,  0.0126, -0.2150, -0.3200],\n",
       "           [ 2.4111,  2.4286,  2.4286,  ..., -0.4076, -0.0049,  0.1001]],\n",
       " \n",
       "          [[ 2.6400,  2.6226,  2.5877,  ...,  1.6640,  1.0888,  0.4788],\n",
       "           [ 2.6400,  2.6226,  2.5877,  ...,  1.8383,  1.0017,  0.7402],\n",
       "           [ 2.6400,  2.6226,  2.5877,  ...,  1.9951,  0.7054,  0.5485],\n",
       "           ...,\n",
       "           [ 2.6226,  2.6400,  2.6400,  ..., -0.8807, -1.1247, -1.2816],\n",
       "           [ 2.5529,  2.5703,  2.5703,  ..., -0.7936, -0.9678, -1.0376],\n",
       "           [ 2.4657,  2.4657,  2.4831,  ..., -1.1247, -0.7064, -0.5495]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.1999, -0.1486, -0.1999,  ..., -0.8335, -0.7822, -0.5938],\n",
       "           [ 0.3481,  0.4851,  0.4851,  ..., -0.8164, -0.7650, -0.6281],\n",
       "           [ 0.9303,  1.1529,  1.2043,  ..., -0.8335, -0.7993, -0.7822],\n",
       "           ...,\n",
       "           [ 2.0777,  2.0948,  2.0434,  ..., -1.1932, -1.2445, -1.2617],\n",
       "           [ 2.0605,  2.0263,  1.9578,  ..., -1.2617, -1.2788, -1.2788],\n",
       "           [ 2.0777,  2.0263,  1.9407,  ..., -1.3130, -1.2959, -1.2617]],\n",
       " \n",
       "          [[-0.2675, -0.2325, -0.2850,  ..., -0.9503, -0.8978, -0.7052],\n",
       "           [ 0.2752,  0.4153,  0.3978,  ..., -0.9503, -0.8803, -0.7402],\n",
       "           [ 0.8704,  1.0980,  1.1331,  ..., -0.9678, -0.9153, -0.8978],\n",
       "           ...,\n",
       "           [ 1.4832,  1.5007,  1.4657,  ..., -1.2829, -1.3354, -1.3529],\n",
       "           [ 1.4657,  1.4307,  1.3606,  ..., -1.3529, -1.3704, -1.3704],\n",
       "           [ 1.4657,  1.3957,  1.3256,  ..., -1.4055, -1.3880, -1.3529]],\n",
       " \n",
       "          [[-0.2532, -0.2184, -0.3055,  ..., -0.8284, -0.7761, -0.5495],\n",
       "           [ 0.2871,  0.4091,  0.3742,  ..., -0.8110, -0.7587, -0.5844],\n",
       "           [ 0.8622,  1.0714,  1.0888,  ..., -0.8284, -0.7936, -0.7413],\n",
       "           ...,\n",
       "           [-0.5495, -0.5495, -0.5844,  ..., -1.1596, -1.2119, -1.2119],\n",
       "           [-0.5495, -0.5844, -0.6541,  ..., -1.2293, -1.2467, -1.2293],\n",
       "           [-0.5147, -0.5844, -0.6715,  ..., -1.2816, -1.2641, -1.2119]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8208,  1.8037,  1.8037,  ...,  2.2147,  2.2147,  2.2147],\n",
       "           [ 1.8550,  1.8379,  1.8550,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 1.8893,  1.8893,  1.9064,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [ 0.7248,  0.6563,  0.6734,  ...,  2.0777,  2.0777,  2.1119],\n",
       "           [ 0.8104,  0.7248,  0.8104,  ...,  2.0605,  2.0777,  2.0948],\n",
       "           [ 0.7419,  0.6392,  0.6734,  ...,  2.0948,  2.1119,  2.0948]],\n",
       " \n",
       "          [[ 1.9734,  1.9559,  1.9559,  ...,  2.0259,  2.0259,  2.0259],\n",
       "           [ 2.0084,  1.9909,  2.0084,  ...,  2.0084,  2.0084,  2.0084],\n",
       "           [ 2.0434,  2.0434,  2.0609,  ...,  2.0084,  2.0084,  2.0084],\n",
       "           ...,\n",
       "           [ 0.6254,  0.5728,  0.6254,  ...,  0.4853,  0.5028,  0.5378],\n",
       "           [ 0.7129,  0.6779,  0.7829,  ...,  0.5203,  0.5378,  0.5553],\n",
       "           [ 0.6429,  0.5728,  0.6429,  ...,  0.5553,  0.5728,  0.5553]],\n",
       " \n",
       "          [[ 2.2914,  2.2740,  2.2740,  ...,  2.1520,  2.1520,  2.1520],\n",
       "           [ 2.3263,  2.3088,  2.3263,  ...,  2.1520,  2.1520,  2.1520],\n",
       "           [ 2.3611,  2.3611,  2.3786,  ...,  2.1694,  2.1694,  2.1694],\n",
       "           ...,\n",
       "           [ 0.6879,  0.6356,  0.6879,  ..., -0.7936, -0.7936, -0.7936],\n",
       "           [ 0.7751,  0.7402,  0.8622,  ..., -0.8110, -0.7936, -0.7761],\n",
       "           [ 0.7054,  0.6531,  0.7054,  ..., -0.7761, -0.7587, -0.7761]]],\n",
       " \n",
       " \n",
       "         [[[-0.9020, -0.9020, -0.8678,  ..., -1.1247, -1.0904, -1.0733],\n",
       "           [-0.9020, -0.8678, -0.8507,  ..., -1.1075, -1.0562, -1.0048],\n",
       "           [-0.9020, -0.8678, -0.8335,  ..., -1.0562, -1.0390, -1.0219],\n",
       "           ...,\n",
       "           [-0.8335, -0.7308, -0.7137,  ..., -0.1828, -0.1828, -0.1486],\n",
       "           [-1.0390, -1.0048, -0.9363,  ..., -0.2342, -0.2171, -0.1486],\n",
       "           [-0.9020, -0.9363, -1.0219,  ..., -0.2513, -0.2171, -0.1657]],\n",
       " \n",
       "          [[-1.2654, -1.2654, -1.2304,  ..., -1.3179, -1.2829, -1.2654],\n",
       "           [-1.2654, -1.2304, -1.2129,  ..., -1.3354, -1.2829, -1.2304],\n",
       "           [-1.2654, -1.2304, -1.1954,  ..., -1.2829, -1.2654, -1.2479],\n",
       "           ...,\n",
       "           [-1.3354, -1.2129, -1.1954,  ..., -0.6176, -0.6176, -0.5826],\n",
       "           [-1.6155, -1.5630, -1.4580,  ..., -0.6702, -0.6527, -0.5826],\n",
       "           [-1.5455, -1.5630, -1.5980,  ..., -0.6877, -0.6527, -0.6001]],\n",
       " \n",
       "          [[-1.3687, -1.3687, -1.3339,  ..., -1.3687, -1.3339, -1.3164],\n",
       "           [-1.3687, -1.3339, -1.3164,  ..., -1.4036, -1.3513, -1.2990],\n",
       "           [-1.3687, -1.3339, -1.2990,  ..., -1.3513, -1.3339, -1.3164],\n",
       "           ...,\n",
       "           [-1.4384, -1.3164, -1.2990,  ..., -0.7936, -0.7587, -0.7238],\n",
       "           [-1.6824, -1.6476, -1.5430,  ..., -0.8458, -0.8110, -0.7238],\n",
       "           [-1.5779, -1.6127, -1.6650,  ..., -0.8633, -0.7936, -0.7413]]]]),\n",
       " tensor([ 1,  1,  1,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  1,\n",
       "          0,  1,  0,  1,  0,  0,  0,  0,  1,  0,  1,  1,  0,  1,\n",
       "          0,  0,  0,  1])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(testloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load in a model such as [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5). Let's print out the model architecture so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.torch/models/densenet121-a639ec97.pth\n",
      "100%|██████████| 32342954/32342954 [00:00<00:00, 33782142.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built out of two main parts, the features and the classifier. The features part is a stack of convolutional layers and overall works as a feature detector that can be fed into a classifier. The classifier part is a single fully-connected layer `(classifier): Linear(in_features=1024, out_features=1000)`. This layer was trained on the ImageNet dataset, so it won't work for our specific problem. That means we need to replace the classifier, but the features will work perfectly on their own. In general, I think about pre-trained networks as amazingly good feature detectors that can be used as the input for simple feed-forward classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model built, we need to train the classifier. However, now we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use the GPU to do the calculations. The linear algebra computations are done in parallel on the GPU leading to 100x increased training speeds. It's also possible to train on multiple GPUs, further decreasing training time.\n",
    "\n",
    "PyTorch, along with pretty much every other deep learning framework, uses [CUDA](https://developer.nvidia.com/cuda-zone) to efficiently compute the forward and backwards passes on the GPU. In PyTorch, you move your model parameters and other tensors to the GPU memory using `model.to('cuda')`. You can move them back from the GPU with `model.to('cpu')` which you'll commonly do when you need to operate on the network output outside of PyTorch. As a demonstration of the increased speed, I'll compare how long it takes to perform a forward and backward pass with and without a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cpu; Time per batch: 5.552 seconds\n",
      "DEVICE = cuda; Time per batch: 0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "for device in ['cpu', 'cuda']:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Move input and label tensors to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"DEVICE = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write device agnostic code which will automatically use CUDA if it's enabled like so:\n",
    "```python\n",
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "...\n",
    "\n",
    "# then whenever you get a new Tensor or Module\n",
    "# this won't copy if they are already on the desired device\n",
    "input = data.to(device)\n",
    "model = MyModule(...).to(device)\n",
    "```\n",
    "\n",
    "From here, I'll let you finish training the model. The process is the same as before except now your model is much more powerful. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train a pretrained models to classify the cat and dog images. Continue with the DenseNet model, or try ResNet, it's also a good model to try out first. Make sure you are only training the classifier and the parameters for the features part are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a model with a pre-trained network\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3...  Loss: 0.2509\n",
      "Epoch: 1/3...  Loss: 0.1873\n",
      "Epoch: 1/3...  Loss: 0.1741\n",
      "Epoch: 1/3...  Loss: 0.1861\n",
      "Epoch: 1/3...  Loss: 0.1646\n",
      "Epoch: 1/3...  Loss: 0.1461\n",
      "Epoch: 1/3...  Loss: 0.1488\n",
      "Epoch: 1/3...  Loss: 0.1648\n",
      "Epoch: 2/3...  Loss: 0.0366\n",
      "Epoch: 2/3...  Loss: 0.1493\n",
      "Epoch: 2/3...  Loss: 0.1743\n",
      "Epoch: 2/3...  Loss: 0.1269\n",
      "Epoch: 2/3...  Loss: 0.1691\n",
      "Epoch: 2/3...  Loss: 0.1506\n",
      "Epoch: 2/3...  Loss: 0.1488\n",
      "Epoch: 2/3...  Loss: 0.1247\n",
      "Epoch: 2/3...  Loss: 0.1326\n",
      "Epoch: 3/3...  Loss: 0.0548\n",
      "Epoch: 3/3...  Loss: 0.1528\n",
      "Epoch: 3/3...  Loss: 0.1379\n",
      "Epoch: 3/3...  Loss: 0.1337\n",
      "Epoch: 3/3...  Loss: 0.1360\n",
      "Epoch: 3/3...  Loss: 0.1366\n",
      "Epoch: 3/3...  Loss: 0.1280\n",
      "Epoch: 3/3...  Loss: 0.1446\n",
      "Epoch: 3/3...  Loss: 0.1391\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "print_every = 40\n",
    "steps = 0\n",
    "\n",
    "# change to cuda\n",
    "model.to('cuda')\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5639],\n",
       "          [ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5468],\n",
       "          [ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5639],\n",
       "          ...,\n",
       "          [-0.3198, -0.3027, -0.2684,  ...,  0.6734,  0.6392,  0.6734],\n",
       "          [-0.2513, -0.2171, -0.1828,  ...,  0.7077,  0.6734,  0.6734],\n",
       "          [-0.2171, -0.1486, -0.1657,  ...,  0.7762,  0.7419,  0.7077]],\n",
       "\n",
       "         [[ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5532],\n",
       "          [ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5357],\n",
       "          [ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5532],\n",
       "          ...,\n",
       "          [-0.5651, -0.5301, -0.4951,  ...,  0.6078,  0.5728,  0.5903],\n",
       "          [-0.4951, -0.4426, -0.3901,  ...,  0.5728,  0.5728,  0.5728],\n",
       "          [-0.4426, -0.3725, -0.3725,  ...,  0.6078,  0.5903,  0.5903]],\n",
       "\n",
       "         [[ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.7054],\n",
       "          [ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.6879],\n",
       "          [ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.7054],\n",
       "          ...,\n",
       "          [-0.8458, -0.8633, -0.8633,  ..., -0.0790, -0.1138, -0.0964],\n",
       "          [-0.8284, -0.8633, -0.8633,  ..., -0.1312, -0.1487, -0.1138],\n",
       "          [-0.7936, -0.8284, -0.8807,  ..., -0.1661, -0.1661, -0.1312]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1462,  2.1290,  2.1633,  ...,  1.9235,  2.2147,  2.1975],\n",
       "          [ 2.1633,  2.1975,  2.1975,  ...,  1.9407,  2.2147,  2.1804],\n",
       "          [ 2.1633,  2.2318,  2.2318,  ...,  1.9407,  2.2147,  2.1633],\n",
       "          ...,\n",
       "          [ 1.7009,  1.5468,  1.4269,  ...,  1.6667,  1.6838,  1.6838],\n",
       "          [ 1.6667,  1.5468,  1.4612,  ...,  1.7352,  1.8208,  1.9064],\n",
       "          [ 1.4612,  1.5810,  1.5639,  ...,  1.8550,  1.9064,  1.9407]],\n",
       "\n",
       "         [[ 2.3235,  2.3410,  2.3761,  ...,  2.0959,  2.3936,  2.3761],\n",
       "          [ 2.3235,  2.4111,  2.4111,  ...,  2.1134,  2.3936,  2.3585],\n",
       "          [ 2.3060,  2.4286,  2.4286,  ...,  2.0959,  2.3761,  2.3235],\n",
       "          ...,\n",
       "          [ 1.8333,  1.6758,  1.5707,  ...,  1.7458,  1.7633,  1.7633],\n",
       "          [ 1.7808,  1.6758,  1.6057,  ...,  1.7983,  1.8859,  1.9909],\n",
       "          [ 1.5532,  1.7283,  1.7108,  ...,  1.9209,  1.9734,  2.0084]],\n",
       "\n",
       "         [[ 2.6051,  2.5006,  2.5529,  ...,  2.2740,  2.5703,  2.5529],\n",
       "          [ 2.6226,  2.5703,  2.5877,  ...,  2.3437,  2.6051,  2.5703],\n",
       "          [ 2.5877,  2.6051,  2.6051,  ...,  2.3786,  2.6226,  2.6051],\n",
       "          ...,\n",
       "          [ 2.0648,  1.9080,  1.7860,  ...,  1.8731,  1.8905,  1.8905],\n",
       "          [ 2.0125,  1.8905,  1.7860,  ...,  1.9777,  2.0823,  2.1694],\n",
       "          [ 1.7337,  1.8905,  1.8731,  ...,  2.1520,  2.2043,  2.2391]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0159,  0.9988,  0.9646,  ...,  2.0263,  2.0263,  2.0263],\n",
       "          [ 0.8618,  0.9132,  0.9474,  ...,  2.0434,  2.0263,  2.0263],\n",
       "          [ 0.8789,  0.9132,  0.9474,  ...,  2.0263,  2.0263,  2.0263],\n",
       "          ...,\n",
       "          [ 0.9988,  1.0331,  1.0844,  ..., -0.2513, -0.2513, -0.2513],\n",
       "          [ 0.9988,  0.9303,  0.8618,  ..., -0.2684, -0.2684, -0.2684],\n",
       "          [ 0.9646,  0.7762,  0.5193,  ..., -0.2856, -0.2856, -0.2856]],\n",
       "\n",
       "         [[ 1.2031,  1.1856,  1.1506,  ...,  2.3585,  2.3585,  2.3585],\n",
       "          [ 1.0455,  1.0980,  1.1331,  ...,  2.3761,  2.3585,  2.3585],\n",
       "          [ 1.0630,  1.0980,  1.1331,  ...,  2.3585,  2.3410,  2.3410],\n",
       "          ...,\n",
       "          [ 1.0630,  1.0980,  1.1506,  ..., -0.2150, -0.2150, -0.2150],\n",
       "          [ 1.0630,  0.9930,  0.9230,  ..., -0.2325, -0.2325, -0.2325],\n",
       "          [ 1.0280,  0.8354,  0.5728,  ..., -0.2500, -0.2500, -0.2500]],\n",
       "\n",
       "         [[ 1.1934,  1.1759,  1.1411,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 1.0365,  1.0888,  1.1237,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          [ 1.0365,  1.0888,  1.1237,  ...,  2.6400,  2.6400,  2.6400],\n",
       "          ...,\n",
       "          [ 0.9319,  0.9668,  1.0191,  ..., -0.0441, -0.0441, -0.0441],\n",
       "          [ 0.9145,  0.8448,  0.7751,  ..., -0.0790, -0.0790, -0.0790],\n",
       "          [ 0.8622,  0.6705,  0.4091,  ..., -0.1312, -0.1312, -0.1312]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1254,  0.0912,  0.0741,  ..., -0.1999, -0.1828, -0.2342],\n",
       "          [ 0.1426,  0.1426,  0.1254,  ..., -0.1657, -0.1828, -0.1999],\n",
       "          [ 0.1597,  0.1768,  0.1597,  ..., -0.1314, -0.1314, -0.1486],\n",
       "          ...,\n",
       "          [-1.4843, -1.4500, -1.4158,  ..., -0.3541, -0.3027, -0.3027],\n",
       "          [-1.5014, -1.4672, -1.3987,  ..., -0.3369, -0.3198, -0.3541],\n",
       "          [-1.4672, -1.4500, -1.4500,  ..., -0.3712, -0.3541, -0.3883]],\n",
       "\n",
       "         [[ 0.1877,  0.1527,  0.1352,  ...,  0.7654,  0.7829,  0.7829],\n",
       "          [ 0.1352,  0.1352,  0.1352,  ...,  0.7654,  0.7654,  0.7654],\n",
       "          [ 0.1352,  0.1527,  0.1527,  ...,  0.7654,  0.7654,  0.7829],\n",
       "          ...,\n",
       "          [-1.2129, -1.1954, -1.1779,  ...,  0.2227,  0.2752,  0.2577],\n",
       "          [-1.2304, -1.1954, -1.1604,  ...,  0.2402,  0.2577,  0.2052],\n",
       "          [-1.1954, -1.1954, -1.2129,  ...,  0.2052,  0.2052,  0.1702]],\n",
       "\n",
       "         [[ 0.3219,  0.2696,  0.2348,  ...,  0.8622,  0.8622,  0.8274],\n",
       "          [ 0.3045,  0.3045,  0.2348,  ...,  0.8099,  0.8099,  0.7576],\n",
       "          [ 0.3393,  0.3045,  0.2871,  ...,  0.7576,  0.7228,  0.6705],\n",
       "          ...,\n",
       "          [-0.8981, -0.8981, -0.8981,  ..., -0.2358, -0.1487, -0.1138],\n",
       "          [-0.9330, -0.9156, -0.8981,  ..., -0.2010, -0.1312, -0.0964],\n",
       "          [-0.9156, -0.9330, -0.9504,  ..., -0.2010, -0.1312, -0.1138]]],\n",
       "\n",
       "\n",
       "        [[[-1.6898, -1.7069, -1.6898,  ...,  0.1254,  0.1254,  0.1254],\n",
       "          [-1.6898, -1.7069, -1.6898,  ...,  0.1254,  0.1254,  0.1254],\n",
       "          [-1.6898, -1.7069, -1.6898,  ...,  0.1254,  0.1254,  0.1254],\n",
       "          ...,\n",
       "          [ 0.7933,  0.8447,  0.8789,  ..., -1.6384, -1.7412, -1.6727],\n",
       "          [ 0.7762,  0.8276,  0.8789,  ..., -1.5185, -1.6727, -1.6384],\n",
       "          [ 0.7762,  0.8276,  0.8789,  ..., -1.4500, -1.5185, -1.6898]],\n",
       "\n",
       "         [[-1.6681, -1.6856, -1.6681,  ..., -0.0224, -0.0224, -0.0224],\n",
       "          [-1.6681, -1.6856, -1.6681,  ..., -0.0224, -0.0224, -0.0224],\n",
       "          [-1.6681, -1.6856, -1.6681,  ..., -0.0224, -0.0224, -0.0224],\n",
       "          ...,\n",
       "          [ 0.4678,  0.5203,  0.5553,  ..., -1.5805, -1.6506, -1.5805],\n",
       "          [ 0.4503,  0.5028,  0.5553,  ..., -1.4580, -1.5980, -1.5455],\n",
       "          [ 0.4503,  0.5028,  0.5553,  ..., -1.3880, -1.4405, -1.5980]],\n",
       "\n",
       "         [[-1.5953, -1.6127, -1.5953,  ..., -0.2358, -0.2358, -0.2358],\n",
       "          [-1.5953, -1.6127, -1.5953,  ..., -0.2358, -0.2358, -0.2358],\n",
       "          [-1.5953, -1.6127, -1.5953,  ..., -0.2358, -0.2358, -0.2358],\n",
       "          ...,\n",
       "          [ 0.3219,  0.3742,  0.4091,  ..., -1.5604, -1.5953, -1.5081],\n",
       "          [ 0.3045,  0.3568,  0.4091,  ..., -1.4384, -1.5430, -1.4907],\n",
       "          [ 0.3045,  0.3568,  0.4091,  ..., -1.3687, -1.3861, -1.5430]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0502,  1.0844,  1.1015,  ..., -0.4397, -0.4226, -0.4568],\n",
       "          [ 0.4679,  0.4851,  0.5022,  ..., -0.4226, -0.4226, -0.4397],\n",
       "          [ 0.2967,  0.3138,  0.3309,  ..., -0.4568, -0.4568, -0.4739],\n",
       "          ...,\n",
       "          [-1.7412, -1.7240, -1.7412,  ..., -0.6109, -0.6109, -0.6281],\n",
       "          [-1.7069, -1.6898, -1.7069,  ..., -0.6281, -0.6281, -0.6109],\n",
       "          [-1.6898, -1.6898, -1.6898,  ..., -0.6452, -0.6281, -0.6109]],\n",
       "\n",
       "         [[ 0.7479,  0.7829,  0.8004,  ..., -0.4426, -0.4426, -0.4601],\n",
       "          [ 0.1702,  0.1877,  0.2052,  ..., -0.4426, -0.4251, -0.4426],\n",
       "          [ 0.0476,  0.0476,  0.0651,  ..., -0.4601, -0.4601, -0.4776],\n",
       "          ...,\n",
       "          [-1.5105, -1.4930, -1.4930,  ..., -0.6352, -0.6176, -0.6352],\n",
       "          [-1.4755, -1.4580, -1.4580,  ..., -0.6527, -0.6352, -0.6176],\n",
       "          [-1.4580, -1.4580, -1.4405,  ..., -0.6527, -0.6352, -0.6176]],\n",
       "\n",
       "         [[ 0.3916,  0.4265,  0.4265,  ..., -0.4624, -0.4798, -0.5147],\n",
       "          [-0.1312, -0.0964, -0.0790,  ..., -0.4450, -0.4798, -0.4973],\n",
       "          [-0.1661, -0.1661, -0.1487,  ..., -0.4798, -0.5147, -0.5321],\n",
       "          ...,\n",
       "          [-0.8807, -0.9330, -0.9853,  ..., -0.6367, -0.6715, -0.6890],\n",
       "          [-0.8633, -0.8981, -0.9330,  ..., -0.6541, -0.6715, -0.6715],\n",
       "          [-0.8284, -0.8981, -0.9330,  ..., -0.6715, -0.6715, -0.6715]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5639],\n",
       "           [ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5468],\n",
       "           [ 1.5468,  1.5639,  1.5639,  ...,  1.5639,  1.5639,  1.5639],\n",
       "           ...,\n",
       "           [-0.3198, -0.3027, -0.2684,  ...,  0.6734,  0.6392,  0.6734],\n",
       "           [-0.2513, -0.2171, -0.1828,  ...,  0.7077,  0.6734,  0.6734],\n",
       "           [-0.2171, -0.1486, -0.1657,  ...,  0.7762,  0.7419,  0.7077]],\n",
       " \n",
       "          [[ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5532],\n",
       "           [ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5357],\n",
       "           [ 1.5357,  1.5532,  1.5532,  ...,  1.5532,  1.5532,  1.5532],\n",
       "           ...,\n",
       "           [-0.5651, -0.5301, -0.4951,  ...,  0.6078,  0.5728,  0.5903],\n",
       "           [-0.4951, -0.4426, -0.3901,  ...,  0.5728,  0.5728,  0.5728],\n",
       "           [-0.4426, -0.3725, -0.3725,  ...,  0.6078,  0.5903,  0.5903]],\n",
       " \n",
       "          [[ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.7054],\n",
       "           [ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.6879],\n",
       "           [ 0.8971,  0.8797,  0.8797,  ...,  0.7054,  0.7054,  0.7054],\n",
       "           ...,\n",
       "           [-0.8458, -0.8633, -0.8633,  ..., -0.0790, -0.1138, -0.0964],\n",
       "           [-0.8284, -0.8633, -0.8633,  ..., -0.1312, -0.1487, -0.1138],\n",
       "           [-0.7936, -0.8284, -0.8807,  ..., -0.1661, -0.1661, -0.1312]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1462,  2.1290,  2.1633,  ...,  1.9235,  2.2147,  2.1975],\n",
       "           [ 2.1633,  2.1975,  2.1975,  ...,  1.9407,  2.2147,  2.1804],\n",
       "           [ 2.1633,  2.2318,  2.2318,  ...,  1.9407,  2.2147,  2.1633],\n",
       "           ...,\n",
       "           [ 1.7009,  1.5468,  1.4269,  ...,  1.6667,  1.6838,  1.6838],\n",
       "           [ 1.6667,  1.5468,  1.4612,  ...,  1.7352,  1.8208,  1.9064],\n",
       "           [ 1.4612,  1.5810,  1.5639,  ...,  1.8550,  1.9064,  1.9407]],\n",
       " \n",
       "          [[ 2.3235,  2.3410,  2.3761,  ...,  2.0959,  2.3936,  2.3761],\n",
       "           [ 2.3235,  2.4111,  2.4111,  ...,  2.1134,  2.3936,  2.3585],\n",
       "           [ 2.3060,  2.4286,  2.4286,  ...,  2.0959,  2.3761,  2.3235],\n",
       "           ...,\n",
       "           [ 1.8333,  1.6758,  1.5707,  ...,  1.7458,  1.7633,  1.7633],\n",
       "           [ 1.7808,  1.6758,  1.6057,  ...,  1.7983,  1.8859,  1.9909],\n",
       "           [ 1.5532,  1.7283,  1.7108,  ...,  1.9209,  1.9734,  2.0084]],\n",
       " \n",
       "          [[ 2.6051,  2.5006,  2.5529,  ...,  2.2740,  2.5703,  2.5529],\n",
       "           [ 2.6226,  2.5703,  2.5877,  ...,  2.3437,  2.6051,  2.5703],\n",
       "           [ 2.5877,  2.6051,  2.6051,  ...,  2.3786,  2.6226,  2.6051],\n",
       "           ...,\n",
       "           [ 2.0648,  1.9080,  1.7860,  ...,  1.8731,  1.8905,  1.8905],\n",
       "           [ 2.0125,  1.8905,  1.7860,  ...,  1.9777,  2.0823,  2.1694],\n",
       "           [ 1.7337,  1.8905,  1.8731,  ...,  2.1520,  2.2043,  2.2391]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0159,  0.9988,  0.9646,  ...,  2.0263,  2.0263,  2.0263],\n",
       "           [ 0.8618,  0.9132,  0.9474,  ...,  2.0434,  2.0263,  2.0263],\n",
       "           [ 0.8789,  0.9132,  0.9474,  ...,  2.0263,  2.0263,  2.0263],\n",
       "           ...,\n",
       "           [ 0.9988,  1.0331,  1.0844,  ..., -0.2513, -0.2513, -0.2513],\n",
       "           [ 0.9988,  0.9303,  0.8618,  ..., -0.2684, -0.2684, -0.2684],\n",
       "           [ 0.9646,  0.7762,  0.5193,  ..., -0.2856, -0.2856, -0.2856]],\n",
       " \n",
       "          [[ 1.2031,  1.1856,  1.1506,  ...,  2.3585,  2.3585,  2.3585],\n",
       "           [ 1.0455,  1.0980,  1.1331,  ...,  2.3761,  2.3585,  2.3585],\n",
       "           [ 1.0630,  1.0980,  1.1331,  ...,  2.3585,  2.3410,  2.3410],\n",
       "           ...,\n",
       "           [ 1.0630,  1.0980,  1.1506,  ..., -0.2150, -0.2150, -0.2150],\n",
       "           [ 1.0630,  0.9930,  0.9230,  ..., -0.2325, -0.2325, -0.2325],\n",
       "           [ 1.0280,  0.8354,  0.5728,  ..., -0.2500, -0.2500, -0.2500]],\n",
       " \n",
       "          [[ 1.1934,  1.1759,  1.1411,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 1.0365,  1.0888,  1.1237,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 1.0365,  1.0888,  1.1237,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [ 0.9319,  0.9668,  1.0191,  ..., -0.0441, -0.0441, -0.0441],\n",
       "           [ 0.9145,  0.8448,  0.7751,  ..., -0.0790, -0.0790, -0.0790],\n",
       "           [ 0.8622,  0.6705,  0.4091,  ..., -0.1312, -0.1312, -0.1312]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.2147,  2.2147,  2.2147,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2147,  2.2147,  2.1975,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.1975,  2.1975,  2.2147,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [ 2.0777,  1.9064,  1.6667,  ...,  2.2147,  2.2147,  2.2147],\n",
       "           [ 2.1462,  2.0605,  1.8722,  ...,  2.1975,  2.1975,  2.2147],\n",
       "           [ 2.1804,  2.1290,  1.9920,  ...,  2.2147,  2.2147,  2.2147]],\n",
       " \n",
       "          [[ 2.3936,  2.3936,  2.3936,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.3936,  2.3936,  2.3761,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.3585,  2.3585,  2.3585,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           ...,\n",
       "           [ 2.2360,  2.0434,  1.7983,  ...,  2.3585,  2.3585,  2.3761],\n",
       "           [ 2.3235,  2.2360,  2.0434,  ...,  2.3761,  2.3761,  2.3936],\n",
       "           [ 2.3585,  2.3060,  2.1660,  ...,  2.3936,  2.3936,  2.3936]],\n",
       " \n",
       "          [[ 2.6051,  2.6051,  2.6051,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6051,  2.6051,  2.5877,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.5877,  2.5877,  2.5877,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [ 2.4831,  2.2914,  2.0474,  ...,  2.5877,  2.5877,  2.5877],\n",
       "           [ 2.5354,  2.4483,  2.2566,  ...,  2.5877,  2.5877,  2.6051],\n",
       "           [ 2.5703,  2.5180,  2.3786,  ...,  2.6051,  2.6051,  2.6051]]],\n",
       " \n",
       " \n",
       "         [[[-1.5870, -1.5699, -1.7240,  ..., -1.7754, -1.6042, -1.3473],\n",
       "           [-1.6384, -1.5870, -1.7412,  ..., -1.6898, -1.5528, -1.3473],\n",
       "           [-1.6555, -1.6384, -1.7412,  ..., -1.6727, -1.5870, -1.4500],\n",
       "           ...,\n",
       "           [-0.2856, -1.3473, -2.1008,  ..., -1.7412, -1.6898, -1.6555],\n",
       "           [-0.4226, -1.4672, -2.1179,  ..., -1.7583, -1.7240, -1.7240],\n",
       "           [-0.6281, -1.6042, -2.1008,  ..., -1.7583, -1.7412, -1.7925]],\n",
       " \n",
       "          [[-1.5980, -1.5455, -1.4930,  ..., -1.5980, -1.6681, -1.6331],\n",
       "           [-1.6331, -1.5105, -1.4405,  ..., -1.5455, -1.6331, -1.5980],\n",
       "           [-1.6155, -1.4930, -1.3880,  ..., -1.5805, -1.6331, -1.6506],\n",
       "           ...,\n",
       "           [ 0.6779, -0.2675, -1.2654,  ..., -1.6331, -1.5980, -1.5630],\n",
       "           [ 0.5028, -0.4426, -1.3354,  ..., -1.4930, -1.4930, -1.4930],\n",
       "           [ 0.2752, -0.6702, -1.3529,  ..., -1.3004, -1.3354, -1.4230]],\n",
       " \n",
       "          [[-0.8981, -0.9330, -1.0201,  ..., -1.1944, -1.2816, -1.2816],\n",
       "           [-0.9330, -0.8981, -0.9504,  ..., -1.1421, -1.2467, -1.2641],\n",
       "           [-0.9330, -0.8807, -0.8633,  ..., -1.1247, -1.2467, -1.3164],\n",
       "           ...,\n",
       "           [ 0.9494,  0.0605, -0.7936,  ..., -1.0376, -1.0027, -0.9504],\n",
       "           [ 0.8274, -0.0964, -0.8458,  ..., -0.9330, -0.9330, -0.9330],\n",
       "           [ 0.6531, -0.2707, -0.8633,  ..., -0.7761, -0.7936, -0.8807]]],\n",
       " \n",
       " \n",
       "         [[[-1.2617, -1.2617, -1.2617,  ..., -1.1589, -0.9192, -0.4911],\n",
       "           [-1.2445, -1.2445, -1.2445,  ..., -1.1760, -0.9534, -0.4397],\n",
       "           [-1.2103, -1.2103, -1.2103,  ..., -1.2103, -0.9534, -0.3369],\n",
       "           ...,\n",
       "           [-1.7754, -1.8953, -2.0837,  ..., -2.1008, -2.0837, -2.0837],\n",
       "           [-1.8782, -1.8610, -2.0323,  ..., -2.0837, -1.9980, -1.9295],\n",
       "           [-1.9124, -1.8782, -1.9809,  ..., -2.0494, -2.0152, -1.9467]],\n",
       " \n",
       "          [[-1.2654, -1.2654, -1.2654,  ..., -1.2479, -1.1429, -0.8978],\n",
       "           [-1.2479, -1.2479, -1.2479,  ..., -1.2654, -1.2129, -0.8978],\n",
       "           [-1.2129, -1.2129, -1.2129,  ..., -1.3179, -1.2479, -0.8277],\n",
       "           ...,\n",
       "           [ 0.3978,  0.4678,  0.4503,  ...,  0.6954,  0.6429,  0.5728],\n",
       "           [ 0.2927,  0.5028,  0.4853,  ...,  0.6429,  0.5553,  0.4678],\n",
       "           [-0.2150,  0.1527,  0.4153,  ...,  0.6078,  0.4678,  0.4153]],\n",
       " \n",
       "          [[-1.0376, -1.0376, -1.0376,  ..., -1.1770, -1.2119, -1.1073],\n",
       "           [-1.0027, -1.0027, -1.0027,  ..., -1.1944, -1.2816, -1.1247],\n",
       "           [-0.9504, -0.9504, -0.9504,  ..., -1.2467, -1.3339, -1.0898],\n",
       "           ...,\n",
       "           [ 1.7163,  1.8208,  1.8034,  ...,  1.6465,  1.6291,  1.5942],\n",
       "           [ 1.5594,  1.8557,  1.8383,  ...,  1.6814,  1.7163,  1.6988],\n",
       "           [ 0.9842,  1.3851,  1.6291,  ...,  1.7163,  1.6988,  1.7337]]]]),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(testloader))\n",
    "#torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above into functions, so they can be used later\n",
    "\n",
    "def do_deep_learning(model, trainloader, epochs, print_every, criterion, optimizer, device='cpu'):\n",
    "    epochs = epochs\n",
    "    print_every = print_every\n",
    "    steps = 0\n",
    "\n",
    "    # change to cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for ii, (inputs, labels) in enumerate(trainloader):\n",
    "            steps += 1\n",
    "\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward passes\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "                      \"Loss: {:.4f}\".format(running_loss/print_every))\n",
    "\n",
    "                running_loss = 0\n",
    "    \n",
    "def check_accuracy_on_test(testloader):    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    \n",
    "    \n",
    "do_deep_learning(model, trainloader, 3, 40, criterion, optimizer, 'gpu')\n",
    "check_accuracy_on_test(testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
